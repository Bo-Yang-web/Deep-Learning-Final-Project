# CS5242 Project


## About

Mamba is a new state space model architecture, we try to use it in prompt generation.
Our work is:
1. generate completions of a user-specified prompt,
2. benchmark the inference speed of this generation,
3. compare mamba with former architectures like transformer in generation quantity, number of parameters
4. etc.

## Installation

Requirements:
- mamba-ssm
- PyTorch 1.12+
- CUDA 11.6+


## Reference

![Mamba](assets/selection.png "Selective State Space")
> **Mamba: Linear-Time Sequence Modeling with Selective State Spaces**\
> Albert Gu*, Tri Dao*\
> Paper: https://arxiv.org/abs/2312.00752

